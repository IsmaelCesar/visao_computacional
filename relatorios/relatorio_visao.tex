\documentclass[journal,onecolumn]{IEEEtran}
\usepackage[utf8]{inputenc}
%\usepackage{hyperref}
\usepackage[sort,compress]{cite}
\usepackage{algorithmic}
\usepackage[ruled,linesnumbered,lined]{algorithm2e}
\usepackage{booktabs}

\usepackage{amsfonts}%Usando fontes para conjuntos numéricos

%\usepackage{titlesec}
\usepackage{color,colortbl,multirow}
\usepackage{xy}
\usepackage{graphicx,url, amsmath, color}
\usepackage{graphicx}
\usepackage{titling}

\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\large#1\end{center}
    \vskip0.5em}%
}
\title{Relatorio de projeto de segunda VA}
\subtitle{Réplica do trabalho:Simple face-detection algorithm based on minimum facial features}
\author{		Ismael Cesar da Silva Araujo
  				Departamento de computação \\
				  Ciência da computação\\
		Universidade Federal Rural de Pernambuco (UFRPE)\\
			ismael.cesar@ufrpe.br}
\date{}
\begin{document}
\maketitle

\section{Introdução}

\section{Conceitos Básicos}
	O algoritmo em \cite{chen2007simple} pode ser dividido em três passos diferentes. 
	Detecção de Pele e cabelo, onde são computados os valores que representam os intervalos de cores de pele e cabelo para a binarização. 
	Quantização de pele e cabelo, onde uma vez binarizadas as detecções são aplicadas operações morfológicas, são computatos os componentes conexos e suas características e aplica-se os filtros de tamanho.
	Ao final, é feita a união das características, procurando intesecções entre retângulos que contém componentes conexos de cabelo e retângulos que contém componente conexos de pele.
	Como as etapas de detecção de pele e de cabelo são feitas de modo ligeiramente diferente, a explanação do funcionamento de ambas foi colocada em duas seções diferentes.
	Porém as etapas de quantização e união de características ocorre de maneira similar, tanto para deteção de cabelo quanto para detecção de pele.
	
	\subsection{Detecção de pele}
	O modelo de cor normalizado, trata-se de um tipo de normalização feita por pixel. 
	Considerando uma com canais RGB (Sigla em inglês para Vermelho, Verde e Azul), 
	A normalização da imagem segundo o modelo de cor normalizada calcularia pra cada pixel o valor contido no canal dividido pela soma de todos os valores dos canais no pixel avaliado~\cite{chen2007simple,loesdau2017chromatic}. 
	Seja $\varepsilon$ um valor da ordem de $10^{-8}$, somado a o denominador para se evitar divisão por zero\eqref{eq:nomalizedColorModel}.	
	\begin{equation}
		\begin{split}
			r  = \frac{R}{R+G+B+\varepsilon} \\\\
			g  = \frac{G}{R+G+B+\varepsilon} \\\\
			b  = \frac{B}{R+G+B+\varepsilon}
			\label{eq:nomalizedColorModel}
		\end{split}
	\end{equation}		
	A normalização das cores da imagem possibilitam a diminuição da sensibilidade do algorítmo de detecção em relação as variações de cores e illuminação.
	Normalizados os intervalos de valores do pixel, é necessário definir funções que avaliam os tons de vermelho  que foram normalizados.
	Tais funções são utilizadas para a definição dos limites superiores e inferiores do intervalo de tons de pele em relação ao canal $r$~\cite{soriano2000using,chen2007simple}.
	\begin{equation}
		\begin{split}
			F_1(r)  = -1.367r^2 + 1.0743r + 0.2 \\
			F_2(r)  = -0.776r^2 + 0.5601r + 0.18
		\end{split}
	\end{equation}
	
	Para o aprimoramento da detecção de pele necessário definir funções para avaliação de tons e branco, em conjunto com valores de matiz ou \textit{Hue} do píxel.
	A avaliação dos tons de branco é feita segundo os valores dos canais $r$ e $g$ do píxel. 
	De modo que o píxel é considerado com algum tom de branco quando $r=0.33$ e $g=0.33$~\cite{chen2007simple}.
	Onde a diferença dos valores dos canais $r$,$g$ e $0.33$ é elevada ao quadrado para para que a mesma só retorne o valor absoluto caso $r$ e $g$ possuam valores menores que $0.33$.
	
	\begin{equation}
		White(r,g) = (r - 0.33)^2 + (g - 0.33)^2 
		\label{eq:whiteValue}
	\end{equation}
	
	Para se constar se o píxel em questão tem algum tom de branco, verifica-se o resultado da comparação entre $White(r,g) > 0.001$.
	Para melhorar o desempenho da detecção de pele é necessário computar a relação entre o modelo de cor HSI (Hue Saturation and Itensity) com o modelo RGB.
	Onde \textit{Hue} descreve a cor que está sendo utilizada, o valor está no intervalo em $[0,360]$ o qual representa o ângulo no circulo unitário.
	\textit{Saturation} representa o nível de puresa da cor, e \textit{Intensity} trata-se de um valor acromático , que representa a itesidade da cor.
	Tanto o valor de \textit{Saturation} quanto o de \textit{Itensity} estão no intervalo de $[0,1]$.
	A figura a seguir ilustra o espaço de cores do modelo HSI. 

		\begin{figure}[htb]
		\begin{center}		
			\includegraphics[scale=0.3]{espaco_hsi.png}
			\caption{Espaço de cores do modelo de cores HSI. fonte:\cite{ibraheem2012understanding} }
			\label{fig:espacoCoresHSI}
		\end{center}
		\end{figure}
	
	Para o algoritmo de detecção de só é necessário computar os valores relativos a \textit{Hue} e \textit{Intensity}.
	O valor de \textit{Hue} é atribuido segundo os valores B e G do esquema RGB. 
	Porém, antes de se computar o valor de \textit{Hue} é necessário computar o ângulo a qual o valor de RGB do pixel correspondem no espaço de cores do esquema HSI Fig.~\ref{fig:espacoCoresHSI}.
	As equações para computar os valores de ângulo, \textit{Hue} e \textit{Intensity} respectivamente encontra-se a seguir:
	
	\begin{equation}
		\theta (R,G,B) = cos^{-1}\left( \frac{0.5((R-G)+(R-B))}{\sqrt{(R-G)^2 +(R-B)(G-R) }} \right)
		\label{eq:angle}	
	\end{equation}
	\begin{equation}
	Hue(B,G,\theta) = 	\begin{cases}
						\theta,  \text{if } B \leq G \\
						360^\circ - \theta,  \text{if } B > G
						\end{cases}
	\label{eq:hue}
	\end{equation}
	\begin{equation}
	I(R,G,B) = 	\frac{1}{3} (R+G+B)
	\label{eq:intensity}
	\end{equation}

	Para se efetuar a detecção de pele numa imagem, faz-se uma binarização da imagem segundo os valores de computados segundo as equações mencionados.
	\begin{equation}
		SkinDetect = \begin{cases}
						1 , \text{ if }\left( g < F_1(r) \cap g > F_2(r) \cap White(r,g) > 0.001 \cap	
											(Hue(B,G,\theta) > 240 \cup Hue(B,G,\theta) \leq 20) \right) \\
						0 , \text{ otherwise }
						\end{cases}
	\end{equation}
	
	\subsection{Detecção de Cabelo}
	
	Para a detecção de tons de cabelo também é efetuada uma binarização da imagem. 
	Ao se fazer a binarização da imagem utiliza apenas as equações \eqref{eq:angle}\eqref{eq:hue}\eqref{eq:intensity} como sub-rotinas.
	Outros valores de comparação considerados são as diferenças entre o valor B e os valores R e G.
	
	\begin{equation}
		HairDetect = \begin{cases}
						1 , \text{ if }\left( (I(R,G,B) < 80 \cap ((B-G)< 15 \cup (B-R) < 15))
										\cup (20 < Hue(B,G,\theta) \leq 40 ) \right) \\
						0 , \text{ otherwise }
						\end{cases}
	\end{equation}
	
	\subsection{Quantização de pele e cabelo}
	
	A etapa de quantização ocorrre de forma semelhante tanto para detecção de cabelo quanto para detecção de pele.
	Uma vez retornada as binarizações da imagens com as detecções de pele e cabelo, são aplicadas operações morfológicas nos retornos \textit{SkinDetetct} e \textit{HairDetect}.
 	Os elementos estruturantes tem de tamanho $5\times 5$.
	A morfologia é calculada para determinar se um pixel numa região pertence a um componente conexo de cabelo ou pelo, ou se o pixel varrido é apenas ruido de detecção.
	
	Em seguida, são computados os componentes conexos e as características dos mesmos de \textit{SkinDetetct} e \textit{HairDetect}.
	As características computadas são o centroide, a área do componente conexo e as posições $(x,y)$ dos pixels mais externos, tanto o mais mais acima e mais a esquerda, quanto o mais abaixo mais a direita.
	Após a computação é feita uma filtragem de componentes conexos.
	Também chamado de filtro de tamanho, ou \textit{size filter}.
	O filtro de tamanho verifica a área de cada componente conexo e exclui o componente conexo cuja área é menor que um limiar qualquer $\lambda$.
	
	\subsection{União de características}	
	
	Para a união de características, faz-se o uso das posições $(x,y)$ computadas dos componentes conexos da detecção de cabelo e pele.
	Isso é feito devido a o fato das posições computadas das features representarem um retângulo que contém o componente conexo.
	Onde para cada componente conexo em $SkinDetect$ é verificado se há intersecção com algum componente conexo em $HairDetect$.
	Caso afirmativo, o algoritmo considera que achou uma face.
	Na figura \ref{fig:intesectRelations} são mostradas as relações de intesecção que são consideradas no algoritmo por simplicidade.
	\begin{figure}[htp]
	\begin{center}
		\includegraphics[scale=0.3]{intersections_skin_hair_components.png}
		\caption{Relações de intersecção entre retângulos que contém cabelo e pele, fonte:\cite{chen2007simple} }			\label{fig:intesectRelations}
	\end{center}
	\end{figure}
	
	\section{Metodologia}
	
	
%Deixar para o final
%	O algoritmo em \citep{chen2007simple} tem como objetivo detectar faces de acordo com o mínimo possível de características
	
\bibliographystyle{IEEEtranS}
\bibliography{bibliography}
\end{document}

